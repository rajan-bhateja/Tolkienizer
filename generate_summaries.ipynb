{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:32.695121Z",
     "start_time": "2025-07-30T11:46:27.042640Z"
    }
   },
   "source": [
    "from langchain_google_genai.llms import GoogleGenerativeAI\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:32.747207Z",
     "start_time": "2025-07-30T11:46:32.721623Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "fb83c111a3d7d13f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:32.870313Z",
     "start_time": "2025-07-30T11:46:32.772596Z"
    }
   },
   "cell_type": "code",
   "source": "llm = GoogleGenerativeAI(model=\"gemini-2.5-flash\")",
   "id": "c8aa862695d4b861",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:32.892120Z",
     "start_time": "2025-07-30T11:46:32.882201Z"
    }
   },
   "cell_type": "code",
   "source": "# response = llm.invoke(\"Summarise the following Tolkien quote in simple English in a paragraph: 'Not all those who wander are lost.'\")",
   "id": "15a6e785be3a665f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:32.909361Z",
     "start_time": "2025-07-30T11:46:32.905854Z"
    }
   },
   "cell_type": "code",
   "source": "# display(Markdown(response))",
   "id": "e2d63de93f68a165",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:33.647109Z",
     "start_time": "2025-07-30T11:46:32.924604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "quotes_df = pd.read_json(\"quotes_with_prompt.json\", lines=True).T\n",
    "quotes_df.rename(columns={0:\"info\"}, inplace=True)\n",
    "quotes_df"
   ],
   "id": "e8b795ee65f8b99b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   info\n",
       "0     {'quote': 'All that is gold does not glitter,\n",
       "...\n",
       "1     {'quote': 'Not all those who wander are lost.\n",
       "...\n",
       "2     {'quote': 'I wish it need not have happened in...\n",
       "3     {'quote': 'I don't know half of you half as we...\n",
       "4     {'quote': 'All we have to decide is what to do...\n",
       "...                                                 ...\n",
       "2989  {'quote': 'He that breaks a thing to find out ...\n",
       "2990  {'quote': 'Home is behind, the world ahead,\n",
       "An...\n",
       "2991  {'quote': 'There is more in you of good than y...\n",
       "2992  {'quote': 'Good Morning!\" said Bilbo, and he m...\n",
       "2993  {'quote': 'In sorrow we must go, but not in de...\n",
       "\n",
       "[2994 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'quote': 'All that is gold does not glitter,\n",
       "...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'quote': 'Not all those who wander are lost.\n",
       "...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'quote': 'I wish it need not have happened in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'quote': 'I don't know half of you half as we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'quote': 'All we have to decide is what to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>{'quote': 'He that breaks a thing to find out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>{'quote': 'Home is behind, the world ahead,\n",
       "An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>{'quote': 'There is more in you of good than y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>{'quote': 'Good Morning!\" said Bilbo, and he m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>{'quote': 'In sorrow we must go, but not in de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2994 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:33.694774Z",
     "start_time": "2025-07-30T11:46:33.685315Z"
    }
   },
   "cell_type": "code",
   "source": "type(quotes_df), type(quotes_df[\"info\"]), type(quotes_df[\"info\"][0]), type(quotes_df[\"info\"][0][\"prompt_template\"])",
   "id": "3daed68ca14e94df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, pandas.core.series.Series, dict, str)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:33.741760Z",
     "start_time": "2025-07-30T11:46:33.734649Z"
    }
   },
   "cell_type": "code",
   "source": "quotes_df[\"info\"][0]",
   "id": "8c1150a4e0c6d2a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': 'All that is gold does not glitter,\\nNot all those who wander are lost;\\nThe old that is strong does not wither,\\nDeep roots are not reached by the frost.\\n\\nFrom the ashes a fire shall be woken,\\nA light from the shadows shall spring;\\nRenewed shall be blade that was broken,\\nThe crownless again shall be king.\\n',\n",
       " 'prompt_template': 'Summarize the following quote in simple English in a paragraph: All that is gold does not glitter,\\nNot all those who wander are lost;\\nThe old that is strong does not wither,\\nDeep roots are not reached by the frost.\\n\\nFrom the ashes a fire shall be woken,\\nA light from the shadows shall spring;\\nRenewed shall be blade that was broken,\\nThe crownless again shall be king.\\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:33.806473Z",
     "start_time": "2025-07-30T11:46:33.800265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# indexing format: quotes_df[column][row][dict_key] -> str\n",
    "quotes_df[\"info\"][0][\"prompt_template\"]"
   ],
   "id": "19e3da7fd56c80c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize the following quote in simple English in a paragraph: All that is gold does not glitter,\\nNot all those who wander are lost;\\nThe old that is strong does not wither,\\nDeep roots are not reached by the frost.\\n\\nFrom the ashes a fire shall be woken,\\nA light from the shadows shall spring;\\nRenewed shall be blade that was broken,\\nThe crownless again shall be king.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:33.852827Z",
     "start_time": "2025-07-30T11:46:33.848101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# constants\n",
    "output_dir = \"summaries/\"\n",
    "batch_size = 100"
   ],
   "id": "76139abb62ae07d8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T11:46:33.872621Z",
     "start_time": "2025-07-30T11:46:33.866032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make sure summaries folder exists\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "id": "22f62a5b466a9423",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T12:12:39.324024Z",
     "start_time": "2025-07-30T11:46:33.922164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load full quotes from original file\n",
    "with open(\"quotes_with_prompt.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    quotes_raw = json.load(f)\n",
    "\n",
    "# Ensure 'quotes' is a list, even if saved as a dict\n",
    "quotes = list(quotes_raw.values()) if isinstance(quotes_raw, dict) else quotes_raw\n",
    "\n",
    "# If summaries exist, merge them in\n",
    "if os.path.exists(\"quotes_with_summary.json\"):\n",
    "    with open(\"quotes_with_summary.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        processed_raw = json.load(f)\n",
    "\n",
    "    processed_quotes = list(processed_raw.values()) if isinstance(processed_raw, dict) else processed_raw\n",
    "\n",
    "    for i in range(min(len(quotes), len(processed_quotes))):\n",
    "        if \"summary\" in processed_quotes[i]:\n",
    "            quotes[i][\"summary\"] = processed_quotes[i][\"summary\"]\n",
    "\n",
    "# Initialize with all quotes that already have summaries\n",
    "quotes_with_summary = [quote for quote in quotes if \"summary\" in quote]\n",
    "\n",
    "# Start batch processing\n",
    "for start in range(0, len(quotes), batch_size):\n",
    "    end = min(start + batch_size, len(quotes))\n",
    "    print(f\"\\nProcessing batch {start} to {end - 1}\")\n",
    "\n",
    "    batch = []\n",
    "\n",
    "    for i in tqdm(range(start, end)):\n",
    "        quote = quotes[i]\n",
    "\n",
    "        # Skip already summarized quotes\n",
    "        if \"summary\" in quote:\n",
    "            batch.append(quote)\n",
    "            continue\n",
    "\n",
    "        # Generate summary using the LLM\n",
    "        summary = llm.invoke(quote[\"prompt_template\"])\n",
    "        quote[\"summary\"] = summary\n",
    "        quotes[i] = quote\n",
    "\n",
    "        batch.append(quote)\n",
    "        quotes_with_summary.append(quote)\n",
    "\n",
    "        time.sleep(2)\n",
    "\n",
    "    # Save current batch\n",
    "    batch_file = os.path.join(output_dir, f\"summary_{start}_{end - 1}.json\")\n",
    "    with open(batch_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(batch, f, ensure_ascii=False)\n",
    "    print(f\"Saved batch to '{batch_file}'\")\n",
    "\n",
    "    # Save all processed quotes so far\n",
    "    with open(\"quotes_with_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(quotes_with_summary, f, ensure_ascii=False)\n",
    "    print(\"Updated quotes_with_summary.json\")"
   ],
   "id": "7ee40a554787de77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing batch 0 to 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 49795.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_0_99.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 100 to 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_100_199.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 200 to 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_200_299.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 300 to 399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_300_399.json'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 400 to 499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_400_499.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 500 to 599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 49760.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_500_599.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 600 to 699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_600_699.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 700 to 799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_700_799.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 800 to 899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 99179.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_800_899.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 900 to 999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_900_999.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1000 to 1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 49807.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1000_1099.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1100 to 1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1100_1199.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1200 to 1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 49713.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1200_1299.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1300 to 1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1300_1399.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1400 to 1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1400_1499.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1500 to 1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1500_1599.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1600 to 1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1600_1699.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1700 to 1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [12:46<00:00,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1700_1799.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1800 to 1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [13:12<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch to 'summaries/summary_1800_1899.json'\n",
      "Updated quotes_with_summary.json\n",
      "\n",
      "Processing batch 1900 to 1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 38\u001B[39m\n\u001B[32m     35\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m     37\u001B[39m \u001B[38;5;66;03m# Generate summary using the LLM\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m38\u001B[39m summary = \u001B[43mllm\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquote\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprompt_template\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     39\u001B[39m quote[\u001B[33m\"\u001B[39m\u001B[33msummary\u001B[39m\u001B[33m\"\u001B[39m] = summary\n\u001B[32m     40\u001B[39m quotes[i] = quote\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:389\u001B[39m, in \u001B[36mBaseLLM.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    378\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    380\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    385\u001B[39m     **kwargs: Any,\n\u001B[32m    386\u001B[39m ) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m    387\u001B[39m     config = ensure_config(config)\n\u001B[32m    388\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[32m--> \u001B[39m\u001B[32m389\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    396\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    397\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    398\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    399\u001B[39m         .generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m]\n\u001B[32m    400\u001B[39m         .text\n\u001B[32m    401\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:766\u001B[39m, in \u001B[36mBaseLLM.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m    757\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    758\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgenerate_prompt\u001B[39m(\n\u001B[32m    759\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    763\u001B[39m     **kwargs: Any,\n\u001B[32m    764\u001B[39m ) -> LLMResult:\n\u001B[32m    765\u001B[39m     prompt_strings = [p.to_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m--> \u001B[39m\u001B[32m766\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_strings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:973\u001B[39m, in \u001B[36mBaseLLM.generate\u001B[39m\u001B[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    958\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m get_llm_cache() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[32m    959\u001B[39m     run_managers = [\n\u001B[32m    960\u001B[39m         callback_manager.on_llm_start(\n\u001B[32m    961\u001B[39m             \u001B[38;5;28mself\u001B[39m._serialized,\n\u001B[32m   (...)\u001B[39m\u001B[32m    971\u001B[39m         )\n\u001B[32m    972\u001B[39m     ]\n\u001B[32m--> \u001B[39m\u001B[32m973\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    974\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    976\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    977\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnew_arg_supported\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnew_arg_supported\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    978\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    979\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) > \u001B[32m0\u001B[39m:\n\u001B[32m    981\u001B[39m     run_managers = [\n\u001B[32m    982\u001B[39m         callback_managers[idx].on_llm_start(\n\u001B[32m    983\u001B[39m             \u001B[38;5;28mself\u001B[39m._serialized,\n\u001B[32m   (...)\u001B[39m\u001B[32m    990\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m missing_prompt_idxs\n\u001B[32m    991\u001B[39m     ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:792\u001B[39m, in \u001B[36mBaseLLM._generate_helper\u001B[39m\u001B[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[39m\n\u001B[32m    781\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate_helper\u001B[39m(\n\u001B[32m    782\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    783\u001B[39m     prompts: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m    788\u001B[39m     **kwargs: Any,\n\u001B[32m    789\u001B[39m ) -> LLMResult:\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    791\u001B[39m         output = (\n\u001B[32m--> \u001B[39m\u001B[32m792\u001B[39m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    793\u001B[39m \u001B[43m                \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    794\u001B[39m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    795\u001B[39m \u001B[43m                \u001B[49m\u001B[38;5;66;43;03m# TODO: support multiple run managers\u001B[39;49;00m\n\u001B[32m    796\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    797\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    798\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    799\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[32m    800\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._generate(prompts, stop=stop)\n\u001B[32m    801\u001B[39m         )\n\u001B[32m    802\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    803\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_google_genai\\llms.py:114\u001B[39m, in \u001B[36mGoogleGenerativeAI._generate\u001B[39m\u001B[34m(self, prompts, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m generations = []\n\u001B[32m    113\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m prompts:\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m     chat_result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    116\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    117\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    118\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    119\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    120\u001B[39m     generations.append(\n\u001B[32m    121\u001B[39m         [\n\u001B[32m    122\u001B[39m             Generation(\n\u001B[32m   (...)\u001B[39m\u001B[32m    130\u001B[39m         ]\n\u001B[32m    131\u001B[39m     )\n\u001B[32m    132\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m LLMResult(generations=generations)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1441\u001B[39m, in \u001B[36mChatGoogleGenerativeAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001B[39m\n\u001B[32m   1414\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_generate\u001B[39m(\n\u001B[32m   1415\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1416\u001B[39m     messages: List[BaseMessage],\n\u001B[32m   (...)\u001B[39m\u001B[32m   1427\u001B[39m     **kwargs: Any,\n\u001B[32m   1428\u001B[39m ) -> ChatResult:\n\u001B[32m   1429\u001B[39m     request = \u001B[38;5;28mself\u001B[39m._prepare_request(\n\u001B[32m   1430\u001B[39m         messages,\n\u001B[32m   1431\u001B[39m         stop=stop,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1439\u001B[39m         **kwargs,\n\u001B[32m   1440\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1441\u001B[39m     response: GenerateContentResponse = \u001B[43m_chat_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1442\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1443\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1444\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgeneration_method\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1445\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdefault_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1446\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1447\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _response_to_result(response)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:231\u001B[39m, in \u001B[36m_chat_with_retry\u001B[39m\u001B[34m(generation_method, **kwargs)\u001B[39m\n\u001B[32m    222\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m    224\u001B[39m params = (\n\u001B[32m    225\u001B[39m     {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs.items() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m _allowed_params_prediction_service}\n\u001B[32m    226\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (request := kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mrequest\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m   (...)\u001B[39m\u001B[32m    229\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m kwargs\n\u001B[32m    230\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m231\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_chat_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:336\u001B[39m, in \u001B[36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[39m\u001B[34m(*args, **kw)\u001B[39m\n\u001B[32m    334\u001B[39m copy = \u001B[38;5;28mself\u001B[39m.copy()\n\u001B[32m    335\u001B[39m wrapped_f.statistics = copy.statistics  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m336\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:475\u001B[39m, in \u001B[36mRetrying.__call__\u001B[39m\u001B[34m(self, fn, *args, **kwargs)\u001B[39m\n\u001B[32m    473\u001B[39m retry_state = RetryCallState(retry_object=\u001B[38;5;28mself\u001B[39m, fn=fn, args=args, kwargs=kwargs)\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m475\u001B[39m     do = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    476\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[32m    477\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:376\u001B[39m, in \u001B[36mBaseRetrying.iter\u001B[39m\u001B[34m(self, retry_state)\u001B[39m\n\u001B[32m    374\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    375\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iter_state.actions:\n\u001B[32m--> \u001B[39m\u001B[32m376\u001B[39m     result = \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:398\u001B[39m, in \u001B[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001B[39m\u001B[34m(rs)\u001B[39m\n\u001B[32m    396\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_post_retry_check_actions\u001B[39m(\u001B[38;5;28mself\u001B[39m, retry_state: \u001B[33m\"\u001B[39m\u001B[33mRetryCallState\u001B[39m\u001B[33m\"\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    397\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m.iter_state.is_explicit_retry \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iter_state.retry_run_result):\n\u001B[32m--> \u001B[39m\u001B[32m398\u001B[39m         \u001B[38;5;28mself\u001B[39m._add_action_func(\u001B[38;5;28;01mlambda\u001B[39;00m rs: \u001B[43mrs\u001B[49m\u001B[43m.\u001B[49m\u001B[43moutcome\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    399\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m    401\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.after \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    447\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception:\n\u001B[32m    400\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[32m    404\u001B[39m         \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\tenacity\\__init__.py:478\u001B[39m, in \u001B[36mRetrying.__call__\u001B[39m\u001B[34m(self, fn, *args, **kwargs)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[32m    477\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m478\u001B[39m         result = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    479\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[32m    480\u001B[39m         retry_state.set_exception(sys.exc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:206\u001B[39m, in \u001B[36m_chat_with_retry.<locals>._chat_with_retry\u001B[39m\u001B[34m(**kwargs)\u001B[39m\n\u001B[32m    203\u001B[39m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[32m    204\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_chat_with_retry\u001B[39m(**kwargs: Any) -> Any:\n\u001B[32m    205\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m206\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgeneration_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    207\u001B[39m     \u001B[38;5;66;03m# Do not retry for these errors.\u001B[39;00m\n\u001B[32m    208\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m google.api_core.exceptions.FailedPrecondition \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001B[39m, in \u001B[36mGenerativeServiceClient.generate_content\u001B[39m\u001B[34m(self, request, model, contents, retry, timeout, metadata)\u001B[39m\n\u001B[32m    865\u001B[39m \u001B[38;5;28mself\u001B[39m._validate_universe_domain()\n\u001B[32m    867\u001B[39m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m868\u001B[39m response = \u001B[43mrpc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    869\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    870\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretry\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    871\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    872\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    873\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    875\u001B[39m \u001B[38;5;66;03m# Done; return the response.\u001B[39;00m\n\u001B[32m    876\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001B[39m, in \u001B[36m_GapicCallable.__call__\u001B[39m\u001B[34m(self, timeout, retry, compression, *args, **kwargs)\u001B[39m\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    129\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mcompression\u001B[39m\u001B[33m\"\u001B[39m] = compression\n\u001B[32m--> \u001B[39m\u001B[32m131\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001B[39m, in \u001B[36mRetry.__call__.<locals>.retry_wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    290\u001B[39m target = functools.partial(func, *args, **kwargs)\n\u001B[32m    291\u001B[39m sleep_generator = exponential_sleep_generator(\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m._initial, \u001B[38;5;28mself\u001B[39m._maximum, multiplier=\u001B[38;5;28mself\u001B[39m._multiplier\n\u001B[32m    293\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m294\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mretry_target\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_predicate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m    \u001B[49m\u001B[43msleep_generator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m    \u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m=\u001B[49m\u001B[43mon_error\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001B[39m, in \u001B[36mretry_target\u001B[39m\u001B[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m    146\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m         result = \u001B[43mtarget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    148\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m inspect.isawaitable(result):\n\u001B[32m    149\u001B[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001B[39m, in \u001B[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    126\u001B[39m         remaining_timeout = \u001B[38;5;28mself\u001B[39m._timeout\n\u001B[32m    128\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mtimeout\u001B[39m\u001B[33m\"\u001B[39m] = remaining_timeout\n\u001B[32m--> \u001B[39m\u001B[32m130\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001B[39m, in \u001B[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     73\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(callable_)\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34merror_remapped_callable\u001B[39m(*args, **kwargs):\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcallable_\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     77\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m grpc.RpcError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m     78\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m exceptions.from_grpc_error(exc) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mexc\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\grpc\\_interceptor.py:277\u001B[39m, in \u001B[36m_UnaryUnaryMultiCallable.__call__\u001B[39m\u001B[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[39m\n\u001B[32m    268\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\n\u001B[32m    269\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    270\u001B[39m     request: Any,\n\u001B[32m   (...)\u001B[39m\u001B[32m    275\u001B[39m     compression: Optional[grpc.Compression] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    276\u001B[39m ) -> Any:\n\u001B[32m--> \u001B[39m\u001B[32m277\u001B[39m     response, ignored_call = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_with_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcredentials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcredentials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    282\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwait_for_ready\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwait_for_ready\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    285\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\grpc\\_interceptor.py:329\u001B[39m, in \u001B[36m_UnaryUnaryMultiCallable._with_call\u001B[39m\u001B[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[39m\n\u001B[32m    326\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[32m    327\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m _FailureOutcome(exception, sys.exc_info()[\u001B[32m2\u001B[39m])\n\u001B[32m--> \u001B[39m\u001B[32m329\u001B[39m call = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_interceptor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mintercept_unary_unary\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcontinuation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclient_call_details\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\n\u001B[32m    331\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    332\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m call.result(), call\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:78\u001B[39m, in \u001B[36m_LoggingClientInterceptor.intercept_unary_unary\u001B[39m\u001B[34m(self, continuation, client_call_details, request)\u001B[39m\n\u001B[32m     64\u001B[39m     grpc_request = {\n\u001B[32m     65\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mpayload\u001B[39m\u001B[33m\"\u001B[39m: request_payload,\n\u001B[32m     66\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mrequestMethod\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mgrpc\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     67\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mdict\u001B[39m(request_metadata),\n\u001B[32m     68\u001B[39m     }\n\u001B[32m     69\u001B[39m     _LOGGER.debug(\n\u001B[32m     70\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSending request for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclient_call_details.method\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m,\n\u001B[32m     71\u001B[39m         extra={\n\u001B[32m   (...)\u001B[39m\u001B[32m     76\u001B[39m         },\n\u001B[32m     77\u001B[39m     )\n\u001B[32m---> \u001B[39m\u001B[32m78\u001B[39m response = \u001B[43mcontinuation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient_call_details\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m logging_enabled:  \u001B[38;5;66;03m# pragma: NO COVER\u001B[39;00m\n\u001B[32m     80\u001B[39m     response_metadata = response.trailing_metadata()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\grpc\\_interceptor.py:315\u001B[39m, in \u001B[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001B[39m\u001B[34m(new_details, request)\u001B[39m\n\u001B[32m    306\u001B[39m (\n\u001B[32m    307\u001B[39m     new_method,\n\u001B[32m    308\u001B[39m     new_timeout,\n\u001B[32m   (...)\u001B[39m\u001B[32m    312\u001B[39m     new_compression,\n\u001B[32m    313\u001B[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001B[32m    314\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m     response, call = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_thunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_method\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwith_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcredentials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_credentials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwait_for_ready\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_wait_for_ready\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    321\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcompression\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnew_compression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    322\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    323\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _UnaryOutcome(response, call)\n\u001B[32m    324\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m grpc.RpcError \u001B[38;5;28;01mas\u001B[39;00m rpc_error:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\grpc\\_channel.py:1195\u001B[39m, in \u001B[36m_UnaryUnaryMultiCallable.with_call\u001B[39m\u001B[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[39m\n\u001B[32m   1183\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwith_call\u001B[39m(\n\u001B[32m   1184\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1185\u001B[39m     request: Any,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1190\u001B[39m     compression: Optional[grpc.Compression] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1191\u001B[39m ) -> Tuple[Any, grpc.Call]:\n\u001B[32m   1192\u001B[39m     (\n\u001B[32m   1193\u001B[39m         state,\n\u001B[32m   1194\u001B[39m         call,\n\u001B[32m-> \u001B[39m\u001B[32m1195\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_blocking\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1196\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcredentials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwait_for_ready\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompression\u001B[49m\n\u001B[32m   1197\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1198\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _end_unary_response_blocking(state, call, \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\Tolkienizer\\.venv\\Lib\\site-packages\\grpc\\_channel.py:1162\u001B[39m, in \u001B[36m_UnaryUnaryMultiCallable._blocking\u001B[39m\u001B[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[39m\n\u001B[32m   1145\u001B[39m state.target = _common.decode(\u001B[38;5;28mself\u001B[39m._target)\n\u001B[32m   1146\u001B[39m call = \u001B[38;5;28mself\u001B[39m._channel.segregated_call(\n\u001B[32m   1147\u001B[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001B[32m   1148\u001B[39m     \u001B[38;5;28mself\u001B[39m._method,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1160\u001B[39m     \u001B[38;5;28mself\u001B[39m._registered_call_handle,\n\u001B[32m   1161\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m1162\u001B[39m event = \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnext_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1163\u001B[39m _handle_event(event, state, \u001B[38;5;28mself\u001B[39m._response_deserializer)\n\u001B[32m   1164\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m state, call\n",
      "\u001B[36mFile \u001B[39m\u001B[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001B[39m, in \u001B[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001B[39m, in \u001B[36mgrpc._cython.cygrpc._next_call_event\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001B[39m, in \u001B[36mgrpc._cython.cygrpc._next_call_event\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001B[39m, in \u001B[36mgrpc._cython.cygrpc._latent_event\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001B[39m, in \u001B[36mgrpc._cython.cygrpc._internal_latent_event\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001B[39m, in \u001B[36mgrpc._cython.cygrpc._next\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
